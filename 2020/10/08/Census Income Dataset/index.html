<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="google-site-verification" content="wt9QnF9m4U8ehNPooNKt3-RfFJ_aA3yh1J3ckY7ieTo" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"muyuhuatang.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Data Science, Classification AnalysisData Cleaning, Feature Engineering, Imputation, and Classification.This Notepad has been designed to be run on top of the Jupyter Tensorflow Docker instance found">
<meta property="og:type" content="article">
<meta property="og:title" content="Huang&#39;s Blog">
<meta property="og:url" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/index.html">
<meta property="og:site_name" content="Huang&#39;s Blog">
<meta property="og:description" content="Data Science, Classification AnalysisData Cleaning, Feature Engineering, Imputation, and Classification.This Notepad has been designed to be run on top of the Jupyter Tensorflow Docker instance found">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_23_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_24_1.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_25_1.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_30_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_33_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_35_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_37_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_39_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_41_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_43_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_45_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_47_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_49_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_51_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_53_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_56_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_58_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_60_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_62_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_64_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_68_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_69_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_70_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_71_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_73_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_74_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_83_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_85_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_87_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_88_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_90_1.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_114_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_118_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_122_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_133_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_138_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_142_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_146_0.png">
<meta property="og:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_147_0.png">
<meta property="article:published_time" content="2020-10-08T07:49:42.000Z">
<meta property="article:modified_time" content="2020-10-08T07:49:42.000Z">
<meta property="article:author" content="Fan Huang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/output_23_0.png">

<link rel="canonical" href="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title> | Huang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Huang's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Huang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Fan Huang">
      <meta itemprop="description" content="The blog site of Fan Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Huang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
            
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-08 15:49:42" itemprop="dateCreated datePublished" datetime="2020-10-08T15:49:42+08:00">2020-10-08</time>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>65k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>48 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Data-Science-Classification-Analysis"><a href="#Data-Science-Classification-Analysis" class="headerlink" title="Data Science, Classification Analysis"></a>Data Science, Classification Analysis</h1><h2 id="Data-Cleaning-Feature-Engineering-Imputation-and-Classification"><a href="#Data-Cleaning-Feature-Engineering-Imputation-and-Classification" class="headerlink" title="Data Cleaning, Feature Engineering, Imputation, and Classification."></a>Data Cleaning, Feature Engineering, Imputation, and Classification.</h2><p>This Notepad has been designed to be run on top of the Jupyter Tensorflow Docker instance found in the link below: </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/jupyter/docker-stacks/tree/master/tensorflow-notebook">https://github.com/jupyter/docker-stacks/tree/master/tensorflow-notebook</a></li>
</ul>
<h2 id="Checking-Number-of-CPU’s-available-to-Docker-container"><a href="#Checking-Number-of-CPU’s-available-to-Docker-container" class="headerlink" title="Checking Number of CPU’s available to Docker container"></a>Checking Number of CPU’s available to Docker container</h2><p>Ideally, and for this Notebook to run in a reasonable time, your Docker container should have 4 cores or more available.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cat /proc/cpuinfo | awk <span class="string">&#x27;/^processor/&#123;print $3&#125;&#x27;</span> | tail <span class="number">-1</span></span><br></pre></td></tr></table></figure>

<pre><code>5</code></pre>
<h2 id="Import-Standard-Python-Libraries"><a href="#Import-Standard-Python-Libraries" class="headerlink" title="Import Standard Python Libraries"></a>Import Standard Python Libraries</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io, os, sys, types, time, datetime, math, random, requests, subprocess, tempfile</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO, BytesIO</span><br></pre></td></tr></table></figure>

<h2 id="Packages-Install"><a href="#Packages-Install" class="headerlink" title="Packages Install"></a>Packages Install</h2><p>We’ll now install a few more libraries. This is an easy way to install libraries in a way that are recognised and managed by conda. Do this once and then comment it out for subsequent runs.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!conda install --yes -c conda-forge missingno</span></span><br><span class="line"><span class="comment">#!conda install --yes -c anaconda requests</span></span><br></pre></td></tr></table></figure>

<h2 id="Packages-Update"><a href="#Packages-Update" class="headerlink" title="Packages Update"></a>Packages Update</h2><p>There’s a lot of packages available to us, and most of them were installed when running the dockerfile that created the docker instance. Let’s make sure they are all up to date. Do this once and then comment it out for subsequent runs.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!conda update --yes --all</span></span><br></pre></td></tr></table></figure>

<h2 id="Packages-Import"><a href="#Packages-Import" class="headerlink" title="Packages Import"></a>Packages Import</h2><p>These are all the packages we’ll be using. Importing individual libraries make it easy for us to use them without having to call the parent libraries.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Data Manipulation </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualization </span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> missingno</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> pandas.plotting <span class="keyword">import</span> scatter_matrix</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Selection and Encoding</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE, RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder, LabelEncoder, label_binarize</span><br><span class="line"></span><br><span class="line"><span class="comment"># Machine learning </span></span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> ske</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, model_selection, tree, preprocessing, metrics, linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression, LogisticRegression, Ridge, Lasso, SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Grid and Random Search</span></span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint <span class="keyword">as</span> sp_randint</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># Metrics</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_fscore_support, roc_curve, auc</span><br><span class="line"></span><br><span class="line"><span class="comment"># Managing Warnings </span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the Figures Inline</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<h2 id="Listing-Installed-Packages"><a href="#Listing-Installed-Packages" class="headerlink" title="Listing Installed Packages"></a>Listing Installed Packages</h2><p>We could list all installed packages to check whether a package has already been installed.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda_packages_list = BytesIO(subprocess.Popen([<span class="string">&quot;conda&quot;</span>, <span class="string">&quot;list&quot;</span>], </span><br><span class="line">                                                         stdout=subprocess.PIPE).communicate()[<span class="number">0</span>])</span><br><span class="line">conda_packages_list = pd.read_csv(conda_packages_list, </span><br><span class="line">                                  names=[<span class="string">&#x27;Package Name&#x27;</span>,<span class="string">&#x27;Version&#x27;</span>,<span class="string">&#x27;Python Version&#x27;</span>,<span class="string">&#x27;Repo&#x27;</span>,<span class="string">&#x27;Other&#x27;</span>], </span><br><span class="line">                                  delim_whitespace=<span class="literal">True</span>, engine=<span class="string">&#x27;python&#x27;</span>, skiprows=<span class="number">3</span>)</span><br><span class="line">conda_packages_list.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Package Name</th>
      <th>Version</th>
      <th>Python Version</th>
      <th>Repo</th>
      <th>Other</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>_libgcc_mutex</td>
      <td>0.1</td>
      <td>conda_forge</td>
      <td>conda-forge</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>_openmp_mutex</td>
      <td>4.5</td>
      <td>1_llvm</td>
      <td>conda-forge</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>absl-py</td>
      <td>0.10.0</td>
      <td>pypi_0</td>
      <td>pypi</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>aiohttp</td>
      <td>3.6.2</td>
      <td>pypi_0</td>
      <td>pypi</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>alembic</td>
      <td>1.4.3</td>
      <td>pyh9f0ad1d_0</td>
      <td>conda-forge</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h2><p>In this Jupyter Notepad, we will using the Census Income Dataset to predict whether an individual’s income exceeds $50K/yr based on census data.</p>
<p>The dataset can be found here: <a target="_blank" rel="noopener" href="https://archive.ics.uci.edu/ml/datasets/adult">https://archive.ics.uci.edu/ml/datasets/adult</a></p>
<h2 id="Data-Download-and-Loading"><a href="#Data-Download-and-Loading" class="headerlink" title="Data Download and Loading"></a>Data Download and Loading</h2><p>Let’s download the data and save it to a folder in our local directory called ‘dataset’. Download it once, and then comment the code out for subsequent runs.</p>
<p>After downloading the data, we load it directly from Disk into a Pandas Dataframe in Memory. Depending on the memory available to the Docker instance, this may be a problem.</p>
<p>The data comes separated into the Training and Test datasets. We will join the two for data exploration, and then separate them again before running our algorithms.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download</span></span><br><span class="line">DATASET = (</span><br><span class="line">    <span class="string">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data&quot;</span>,</span><br><span class="line">    <span class="string">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names&quot;</span>,</span><br><span class="line">    <span class="string">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_data</span>(<span class="params">path=<span class="string">&#x27;dataset&#x27;</span>, urls=DATASET</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        os.mkdir(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        name = os.path.basename(url)</span><br><span class="line">        <span class="keyword">with</span> open(os.path.join(path, name), <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.content)</span><br><span class="line"></span><br><span class="line"><span class="comment">#download_data()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load Training and Test Data Sets</span></span><br><span class="line">headers = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, </span><br><span class="line">           <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, </span><br><span class="line">           <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, </span><br><span class="line">           <span class="string">&#x27;relationship&#x27;</span>, <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, </span><br><span class="line">           <span class="string">&#x27;capital-gain&#x27;</span>, <span class="string">&#x27;capital-loss&#x27;</span>, </span><br><span class="line">           <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>, </span><br><span class="line">           <span class="string">&#x27;predclass&#x27;</span>]</span><br><span class="line">training_raw = pd.read_csv(<span class="string">&#x27;dataset/adult.data&#x27;</span>, </span><br><span class="line">                       header=<span class="literal">None</span>, </span><br><span class="line">                       names=headers, </span><br><span class="line">                       sep=<span class="string">&#x27;,\s&#x27;</span>, </span><br><span class="line">                       na_values=[<span class="string">&quot;?&quot;</span>], </span><br><span class="line">                       engine=<span class="string">&#x27;python&#x27;</span>)</span><br><span class="line">test_raw = pd.read_csv(<span class="string">&#x27;dataset/adult.test&#x27;</span>, </span><br><span class="line">                      header=<span class="literal">None</span>, </span><br><span class="line">                      names=headers, </span><br><span class="line">                      sep=<span class="string">&#x27;,\s&#x27;</span>, </span><br><span class="line">                      na_values=[<span class="string">&quot;?&quot;</span>], </span><br><span class="line">                      engine=<span class="string">&#x27;python&#x27;</span>, </span><br><span class="line">                      skiprows=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Join Datasets</span></span><br><span class="line">dataset_raw = training_raw.append(test_raw)</span><br><span class="line">dataset_raw.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line">dataset_raw.drop(<span class="string">&#x27;index&#x27;</span>,inplace=<span class="literal">True</span>,axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Displaying the size of the Dataframe in Memory</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_size</span>(<span class="params">size_bytes</span>):</span></span><br><span class="line">   <span class="keyword">if</span> size_bytes == <span class="number">0</span>:</span><br><span class="line">       <span class="keyword">return</span> <span class="string">&quot;0B&quot;</span></span><br><span class="line">   size_name = (<span class="string">&quot;Bytes&quot;</span>, <span class="string">&quot;KB&quot;</span>, <span class="string">&quot;MB&quot;</span>, <span class="string">&quot;GB&quot;</span>, <span class="string">&quot;TB&quot;</span>, <span class="string">&quot;PB&quot;</span>, <span class="string">&quot;EB&quot;</span>, <span class="string">&quot;ZB&quot;</span>, <span class="string">&quot;YB&quot;</span>)</span><br><span class="line">   i = int(math.floor(math.log(size_bytes, <span class="number">1024</span>)))</span><br><span class="line">   p = math.pow(<span class="number">1024</span>, i)</span><br><span class="line">   s = round(size_bytes / p, <span class="number">2</span>)</span><br><span class="line">   <span class="keyword">return</span> <span class="string">&quot;%s %s&quot;</span> % (s, size_name[i])</span><br><span class="line">convert_size(dataset_raw.memory_usage().sum())</span><br></pre></td></tr></table></figure>




<pre><code>&#39;5.59 MB&#39;</code></pre>
<h2 id="Data-Exploration-Univariate"><a href="#Data-Exploration-Univariate" class="headerlink" title="Data Exploration - Univariate"></a>Data Exploration - Univariate</h2><p>When exploring our dataset and its features, we have many options available to us. We can explore each feature individually, or compare pairs of features, finding the correlation between. Let’s start with some simple Univariate (one feature) analysis.</p>
<p>Features can be of multiple types:</p>
<ul>
<li><strong>Nominal:</strong>  is for mutual exclusive, but not ordered, categories.</li>
<li><strong>Ordinal:</strong> is one where the order matters but not the difference between values.</li>
<li><strong>Interval:</strong> is a measurement where the difference between two values is meaningful.</li>
<li><strong>Ratio:</strong> has all the properties of an interval variable, and also has a clear definition of 0.0.</li>
</ul>
<p>There are multiple ways of manipulating each feature type, but for simplicity, we’ll define only two feature types:</p>
<ul>
<li><strong>Numerical:</strong> any feature that contains numeric values.</li>
<li><strong>Categorical:</strong> any feature that contains categories, or text.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Describing all the Numerical Features</span></span><br><span class="line">dataset_raw.describe()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>fnlwgt</th>
      <th>education-num</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>48842.000000</td>
      <td>4.884200e+04</td>
      <td>48842.000000</td>
      <td>48842.000000</td>
      <td>48842.000000</td>
      <td>48842.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>38.643585</td>
      <td>1.896641e+05</td>
      <td>10.078089</td>
      <td>1079.067626</td>
      <td>87.502314</td>
      <td>40.422382</td>
    </tr>
    <tr>
      <th>std</th>
      <td>13.710510</td>
      <td>1.056040e+05</td>
      <td>2.570973</td>
      <td>7452.019058</td>
      <td>403.004552</td>
      <td>12.391444</td>
    </tr>
    <tr>
      <th>min</th>
      <td>17.000000</td>
      <td>1.228500e+04</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>28.000000</td>
      <td>1.175505e+05</td>
      <td>9.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>40.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>37.000000</td>
      <td>1.781445e+05</td>
      <td>10.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>40.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>48.000000</td>
      <td>2.376420e+05</td>
      <td>12.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>45.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>90.000000</td>
      <td>1.490400e+06</td>
      <td>16.000000</td>
      <td>99999.000000</td>
      <td>4356.000000</td>
      <td>99.000000</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Describing all the Categorical Features</span></span><br><span class="line">dataset_raw.describe(include=[<span class="string">&#x27;O&#x27;</span>])</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>workclass</th>
      <th>education</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>native-country</th>
      <th>predclass</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>46043</td>
      <td>48842</td>
      <td>48842</td>
      <td>46033</td>
      <td>48842</td>
      <td>48842</td>
      <td>48842</td>
      <td>47985</td>
      <td>48842</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>8</td>
      <td>16</td>
      <td>7</td>
      <td>14</td>
      <td>6</td>
      <td>5</td>
      <td>2</td>
      <td>41</td>
      <td>4</td>
    </tr>
    <tr>
      <th>top</th>
      <td>Private</td>
      <td>HS-grad</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>33906</td>
      <td>15784</td>
      <td>22379</td>
      <td>6172</td>
      <td>19716</td>
      <td>41762</td>
      <td>32650</td>
      <td>43832</td>
      <td>24720</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s have a quick look at our data</span></span><br><span class="line">dataset_raw.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>fnlwgt</th>
      <th>education</th>
      <th>education-num</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
      <th>native-country</th>
      <th>predclass</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>Adm-clerical</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>Handlers-cleaners</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>3</th>
      <td>53</td>
      <td>Private</td>
      <td>234721</td>
      <td>11th</td>
      <td>7</td>
      <td>Married-civ-spouse</td>
      <td>Handlers-cleaners</td>
      <td>Husband</td>
      <td>Black</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>4</th>
      <td>28</td>
      <td>Private</td>
      <td>338409</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Wife</td>
      <td>Black</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>Cuba</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let’s plot the distribution of each feature</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_distribution</span>(<span class="params">dataset, cols=<span class="number">5</span>, width=<span class="number">20</span>, height=<span class="number">15</span>, hspace=<span class="number">0.2</span>, wspace=<span class="number">0.5</span></span>):</span></span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">    fig = plt.figure(figsize=(width,height))</span><br><span class="line">    fig.subplots_adjust(left=<span class="literal">None</span>, bottom=<span class="literal">None</span>, right=<span class="literal">None</span>, top=<span class="literal">None</span>, wspace=wspace, hspace=hspace)</span><br><span class="line">    rows = math.ceil(float(dataset.shape[<span class="number">1</span>]) / cols)</span><br><span class="line">    <span class="keyword">for</span> i, column <span class="keyword">in</span> enumerate(dataset.columns):</span><br><span class="line">        ax = fig.add_subplot(rows, cols, i + <span class="number">1</span>)</span><br><span class="line">        ax.set_title(column)</span><br><span class="line">        <span class="keyword">if</span> dataset.dtypes[column] == np.object:</span><br><span class="line">            g = sns.countplot(y=column, data=dataset)</span><br><span class="line">            substrings = [s.get_text()[:<span class="number">18</span>] <span class="keyword">for</span> s <span class="keyword">in</span> g.get_yticklabels()]</span><br><span class="line">            g.set(yticklabels=substrings)</span><br><span class="line">            plt.xticks(rotation=<span class="number">25</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            g = sns.distplot(dataset[column])</span><br><span class="line">            plt.xticks(rotation=<span class="number">25</span>)</span><br><span class="line">    </span><br><span class="line">plot_distribution(dataset_raw, cols=<span class="number">3</span>, width=<span class="number">20</span>, height=<span class="number">20</span>, hspace=<span class="number">0.45</span>, wspace=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_23_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># How many missing values are there in our dataset?</span></span><br><span class="line">missingno.matrix(dataset_raw, figsize = (<span class="number">30</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure>




<pre><code>&lt;AxesSubplot:&gt;</code></pre>
<p><img src="/2020/10/08/Census%20Income%20Dataset/output_24_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">missingno.bar(dataset_raw, sort=<span class="string">&#x27;ascending&#x27;</span>, figsize = (<span class="number">30</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure>




<pre><code>&lt;AxesSubplot:&gt;</code></pre>
<p><img src="/2020/10/08/Census%20Income%20Dataset/output_25_1.png" alt="png"></p>
<h1 id="Feature-Cleaning-Engineering-and-Imputation"><a href="#Feature-Cleaning-Engineering-and-Imputation" class="headerlink" title="Feature Cleaning, Engineering, and Imputation"></a>Feature Cleaning, Engineering, and Imputation</h1><p><strong>Cleaning:</strong><br>To clean our data, we’ll need to work with:</p>
<ul>
<li><strong>Missing values:</strong> Either omit elements from a dataset that contain missing values or impute them (fill them in).</li>
<li><strong>Special values:</strong> Numeric variables are endowed with several formalized special values including ±Inf, NA and NaN. Calculations involving special values often result in special values, and need to be handled/cleaned.</li>
<li><strong>Outliers:</strong> They should be detected, but not necessarily removed. Their inclusion in the analysis is a statistical decision.</li>
<li><strong>Obvious inconsistencies:</strong> A person’s age cannot be negative, a man cannot be pregnant and an under-aged person cannot possess a drivers license. Find the inconsistencies and plan for them.</li>
</ul>
<p><strong>Engineering:</strong><br>There are multiple techniques for feature engineering:</p>
<ul>
<li><p><strong>Decompose:</strong> Converting 2014-09-20T20:45:40Z into categorical attributes like hour_of_the_day, part_of_day, etc.</p>
</li>
<li><p><strong>Discretization:</strong> We can choose to either discretize some of the continuous variables we have, as some algorithms will perform faster. We are going to do both, and compare the results of the ML algorithms on both discretized and non discretised datasets. We’ll call these datasets:</p>
</li>
<li><p>dataset_bin =&gt; where Continuous variables are Discretised</p>
</li>
<li><p>dataset_con =&gt; where Continuous variables are Continuous </p>
</li>
<li><p><strong>Reframe Numerical Quantities:</strong> Changing from grams to kg, and losing detail might be both wanted and efficient for calculation</p>
</li>
<li><p><strong>Feature Crossing:</strong> Creating new features as a combination of existing features. Could be multiplying numerical features, or combining categorical variables. This is a great way to add domain expertise knowledge to the dataset.</p>
</li>
</ul>
<p><strong>Imputation:</strong><br>We can impute missing values in a number of different ways:</p>
<ul>
<li><strong>Hot-Deck:</strong>    The technique then finds the first missing value and uses the cell value immediately prior to the data that are missing to impute the missing value.</li>
<li><strong>Cold-Deck:</strong> Selects donors from another dataset to complete missing data.</li>
<li><strong>Mean-substitution:</strong> Another imputation technique involves replacing any missing value with the mean of that variable for all other cases, which has the benefit of not changing the sample mean for that variable.</li>
<li><strong>Regression:</strong> A regression model is estimated to predict observed values of a variable based on other variables, and that model is then used to impute values in cases where that variable is missing.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># To perform our data analysis, let&#x27;s create new dataframes.</span></span><br><span class="line">dataset_bin = pd.DataFrame() <span class="comment"># To contain our dataframe with our discretised continuous variables </span></span><br><span class="line">dataset_con = pd.DataFrame() <span class="comment"># To contain our dataframe with our continuous variables </span></span><br></pre></td></tr></table></figure>

<h3 id="Feature-Predclass"><a href="#Feature-Predclass" class="headerlink" title="Feature Predclass"></a>Feature Predclass</h3><p>This is the feature we are trying to predict. We’ll change the string to a binary 0/1. With 1 signifying over $50K.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s fix the Class Feature</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;predclass&#x27;</span>] == <span class="string">&#x27;&gt;50K&#x27;</span>, <span class="string">&#x27;predclass&#x27;</span>] = <span class="number">1</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;predclass&#x27;</span>] == <span class="string">&#x27;&gt;50K.&#x27;</span>, <span class="string">&#x27;predclass&#x27;</span>] = <span class="number">1</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;predclass&#x27;</span>] == <span class="string">&#x27;&lt;=50K&#x27;</span>, <span class="string">&#x27;predclass&#x27;</span>] = <span class="number">0</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;predclass&#x27;</span>] == <span class="string">&#x27;&lt;=50K.&#x27;</span>, <span class="string">&#x27;predclass&#x27;</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">dataset_bin[<span class="string">&#x27;predclass&#x27;</span>] = dataset_raw[<span class="string">&#x27;predclass&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;predclass&#x27;</span>] = dataset_raw[<span class="string">&#x27;predclass&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">1</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;predclass&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_30_0.png" alt="png"></p>
<h3 id="Feature-Age"><a href="#Feature-Age" class="headerlink" title="Feature: Age"></a>Feature: Age</h3><p>We will use the Pandas Cut function to bin the data in equally sized buckets. We will also add our original feature to the dataset_con dataframe.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset_bin[<span class="string">&#x27;age&#x27;</span>] = pd.cut(dataset_raw[<span class="string">&#x27;age&#x27;</span>], <span class="number">10</span>) <span class="comment"># discretised </span></span><br><span class="line">dataset_con[<span class="string">&#x27;age&#x27;</span>] = dataset_raw[<span class="string">&#x27;age&#x27;</span>] <span class="comment"># non-discretised</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>)) </span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.countplot(y=<span class="string">&quot;age&quot;</span>, data=dataset_bin);</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.distplot(dataset_con.loc[dataset_con[<span class="string">&#x27;predclass&#x27;</span>] == <span class="number">1</span>][<span class="string">&#x27;age&#x27;</span>], kde_kws=&#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;&gt;$50K&quot;</span>&#125;);</span><br><span class="line">sns.distplot(dataset_con.loc[dataset_con[<span class="string">&#x27;predclass&#x27;</span>] == <span class="number">0</span>][<span class="string">&#x27;age&#x27;</span>], kde_kws=&#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;&lt;$50K&quot;</span>&#125;);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_33_0.png" alt="png"></p>
<h3 id="Feature-Workclass"><a href="#Feature-Workclass" class="headerlink" title="Feature: Workclass"></a>Feature: Workclass</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Can we bucket some of these groups?</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">3</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;workclass&quot;</span>, data=dataset_raw);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_35_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># There are too many groups here, we can group someof them together.</span></span><br><span class="line"><span class="comment"># Create buckets for Workclass</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;workclass&#x27;</span>] == <span class="string">&#x27;Without-pay&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>] = <span class="string">&#x27;Not Working&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;workclass&#x27;</span>] == <span class="string">&#x27;Never-worked&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>] = <span class="string">&#x27;Not Working&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;workclass&#x27;</span>] == <span class="string">&#x27;Federal-gov&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>] = <span class="string">&#x27;Fed-gov&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;workclass&#x27;</span>] == <span class="string">&#x27;State-gov&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>] = <span class="string">&#x27;Non-fed-gov&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;workclass&#x27;</span>] == <span class="string">&#x27;Local-gov&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>] = <span class="string">&#x27;Non-fed-gov&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;workclass&#x27;</span>] == <span class="string">&#x27;Self-emp-not-inc&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>] = <span class="string">&#x27;Self-emp&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;workclass&#x27;</span>] == <span class="string">&#x27;Self-emp-inc&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>] = <span class="string">&#x27;Self-emp&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset_bin[<span class="string">&#x27;workclass&#x27;</span>] = dataset_raw[<span class="string">&#x27;workclass&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;workclass&#x27;</span>] = dataset_raw[<span class="string">&#x27;workclass&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">2</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;workclass&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_37_0.png" alt="png"></p>
<h3 id="Feature-Occupation"><a href="#Feature-Occupation" class="headerlink" title="Feature: Occupation"></a>Feature: Occupation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Can we bucket some of these groups?</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;occupation&quot;</span>, data=dataset_raw);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_39_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create buckets for Occupation</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Adm-clerical&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Admin&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Armed-Forces&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Military&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Craft-repair&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Manual Labour&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Exec-managerial&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Office Labour&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Farming-fishing&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Manual Labour&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Handlers-cleaners&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Manual Labour&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Machine-op-inspct&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Manual Labour&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Other-service&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Service&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Priv-house-serv&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Service&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Prof-specialty&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Professional&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Protective-serv&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Military&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Sales&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Office Labour&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Tech-support&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Office Labour&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;occupation&#x27;</span>] == <span class="string">&#x27;Transport-moving&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>] = <span class="string">&#x27;Manual Labour&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset_bin[<span class="string">&#x27;occupation&#x27;</span>] = dataset_raw[<span class="string">&#x27;occupation&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;occupation&#x27;</span>] = dataset_raw[<span class="string">&#x27;occupation&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">3</span>))</span><br><span class="line">sns.countplot(y=<span class="string">&quot;occupation&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_41_0.png" alt="png"></p>
<h3 id="Feature-Native-Country"><a href="#Feature-Native-Country" class="headerlink" title="Feature: Native Country"></a>Feature: Native Country</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Can we bucket some of these groups?</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;native-country&quot;</span>, data=dataset_raw);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_43_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Cambodia&#x27;</span>                    , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;SE-Asia&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Canada&#x27;</span>                      , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;British-Commonwealth&#x27;</span>    </span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;China&#x27;</span>                       , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;China&#x27;</span>       </span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Columbia&#x27;</span>                    , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span>    </span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Cuba&#x27;</span>                        , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span>        </span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Dominican-Republic&#x27;</span>          , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Ecuador&#x27;</span>                     , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span>     </span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;El-Salvador&#x27;</span>                 , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span> </span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;England&#x27;</span>                     , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;British-Commonwealth&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;France&#x27;</span>                      , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_1&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Germany&#x27;</span>                     , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_1&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Greece&#x27;</span>                      , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_2&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Guatemala&#x27;</span>                   , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Haiti&#x27;</span>                       , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Holand-Netherlands&#x27;</span>          , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_1&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Honduras&#x27;</span>                    , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Hong&#x27;</span>                        , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;China&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Hungary&#x27;</span>                     , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_2&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;India&#x27;</span>                       , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;British-Commonwealth&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Iran&#x27;</span>                        , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_2&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Ireland&#x27;</span>                     , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;British-Commonwealth&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Italy&#x27;</span>                       , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_1&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Jamaica&#x27;</span>                     , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Japan&#x27;</span>                       , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;APAC&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Laos&#x27;</span>                        , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;SE-Asia&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Mexico&#x27;</span>                      , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Nicaragua&#x27;</span>                   , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Outlying-US(Guam-USVI-etc)&#x27;</span>  , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Peru&#x27;</span>                        , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Philippines&#x27;</span>                 , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;SE-Asia&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Poland&#x27;</span>                      , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_2&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Portugal&#x27;</span>                    , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_2&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Puerto-Rico&#x27;</span>                 , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Scotland&#x27;</span>                    , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;British-Commonwealth&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;South&#x27;</span>                       , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_2&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Taiwan&#x27;</span>                      , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;China&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Thailand&#x27;</span>                    , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;SE-Asia&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Trinadad&amp;Tobago&#x27;</span>             , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;South-America&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;United-States&#x27;</span>               , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;United-States&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Vietnam&#x27;</span>                     , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;SE-Asia&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;native-country&#x27;</span>] == <span class="string">&#x27;Yugoslavia&#x27;</span>                  , <span class="string">&#x27;native-country&#x27;</span>] = <span class="string">&#x27;Euro_Group_2&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset_bin[<span class="string">&#x27;native-country&#x27;</span>] = dataset_raw[<span class="string">&#x27;native-country&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;native-country&#x27;</span>] = dataset_raw[<span class="string">&#x27;native-country&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">4</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;native-country&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_45_0.png" alt="png"></p>
<h3 id="Feature-Education"><a href="#Feature-Education" class="headerlink" title="Feature: Education"></a>Feature: Education</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Can we bucket some of these groups?</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;education&quot;</span>, data=dataset_raw);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_47_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;10th&#x27;</span>          , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;11th&#x27;</span>          , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;12th&#x27;</span>          , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;1st-4th&#x27;</span>       , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;5th-6th&#x27;</span>       , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;7th-8th&#x27;</span>       , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;9th&#x27;</span>           , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Assoc-acdm&#x27;</span>    , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Associate&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Assoc-voc&#x27;</span>     , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Associate&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Bachelors&#x27;</span>     , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Bachelors&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Doctorate&#x27;</span>     , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Doctorate&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;HS-Grad&#x27;</span>       , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;HS-Graduate&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Masters&#x27;</span>       , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Masters&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Preschool&#x27;</span>     , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Dropout&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Prof-school&#x27;</span>   , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;Professor&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;education&#x27;</span>] == <span class="string">&#x27;Some-college&#x27;</span>  , <span class="string">&#x27;education&#x27;</span>] = <span class="string">&#x27;HS-Graduate&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset_bin[<span class="string">&#x27;education&#x27;</span>] = dataset_raw[<span class="string">&#x27;education&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;education&#x27;</span>] = dataset_raw[<span class="string">&#x27;education&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">4</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;education&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_49_0.png" alt="png"></p>
<h3 id="Feature-Marital-Status"><a href="#Feature-Marital-Status" class="headerlink" title="Feature: Marital Status"></a>Feature: Marital Status</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Can we bucket some of these groups?</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">3</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;marital-status&quot;</span>, data=dataset_raw);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_51_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>] == <span class="string">&#x27;Never-married&#x27;</span>        , <span class="string">&#x27;marital-status&#x27;</span>] = <span class="string">&#x27;Never-Married&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>] == <span class="string">&#x27;Married-AF-spouse&#x27;</span>    , <span class="string">&#x27;marital-status&#x27;</span>] = <span class="string">&#x27;Married&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>] == <span class="string">&#x27;Married-civ-spouse&#x27;</span>   , <span class="string">&#x27;marital-status&#x27;</span>] = <span class="string">&#x27;Married&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>] == <span class="string">&#x27;Married-spouse-absent&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>] = <span class="string">&#x27;Not-Married&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>] == <span class="string">&#x27;Separated&#x27;</span>            , <span class="string">&#x27;marital-status&#x27;</span>] = <span class="string">&#x27;Separated&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>] == <span class="string">&#x27;Divorced&#x27;</span>             , <span class="string">&#x27;marital-status&#x27;</span>] = <span class="string">&#x27;Separated&#x27;</span></span><br><span class="line">dataset_raw.loc[dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>] == <span class="string">&#x27;Widowed&#x27;</span>              , <span class="string">&#x27;marital-status&#x27;</span>] = <span class="string">&#x27;Widowed&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset_bin[<span class="string">&#x27;marital-status&#x27;</span>] = dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;marital-status&#x27;</span>] = dataset_raw[<span class="string">&#x27;marital-status&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">3</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;marital-status&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_53_0.png" alt="png"></p>
<h3 id="Feature-Final-Weight"><a href="#Feature-Final-Weight" class="headerlink" title="Feature: Final Weight"></a>Feature: Final Weight</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s use the Pandas Cut function to bin the data in equally sized buckets</span></span><br><span class="line">dataset_bin[<span class="string">&#x27;fnlwgt&#x27;</span>] = pd.cut(dataset_raw[<span class="string">&#x27;fnlwgt&#x27;</span>], <span class="number">10</span>)</span><br><span class="line">dataset_con[<span class="string">&#x27;fnlwgt&#x27;</span>] = dataset_raw[<span class="string">&#x27;fnlwgt&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">4</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;fnlwgt&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_56_0.png" alt="png"></p>
<h3 id="Feature-Education-Number"><a href="#Feature-Education-Number" class="headerlink" title="Feature: Education Number"></a>Feature: Education Number</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s use the Pandas Cut function to bin the data in equally sized buckets</span></span><br><span class="line">dataset_bin[<span class="string">&#x27;education-num&#x27;</span>] = pd.cut(dataset_raw[<span class="string">&#x27;education-num&#x27;</span>], <span class="number">10</span>)</span><br><span class="line">dataset_con[<span class="string">&#x27;education-num&#x27;</span>] = dataset_raw[<span class="string">&#x27;education-num&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;education-num&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_58_0.png" alt="png"></p>
<h3 id="Feature-Hours-per-Week"><a href="#Feature-Hours-per-Week" class="headerlink" title="Feature: Hours per Week"></a>Feature: Hours per Week</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s use the Pandas Cut function to bin the data in equally sized buckets</span></span><br><span class="line">dataset_bin[<span class="string">&#x27;hours-per-week&#x27;</span>] = pd.cut(dataset_raw[<span class="string">&#x27;hours-per-week&#x27;</span>], <span class="number">10</span>)</span><br><span class="line">dataset_con[<span class="string">&#x27;hours-per-week&#x27;</span>] = dataset_raw[<span class="string">&#x27;hours-per-week&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">4</span>)) </span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.countplot(y=<span class="string">&quot;hours-per-week&quot;</span>, data=dataset_bin);</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.distplot(dataset_con[<span class="string">&#x27;hours-per-week&#x27;</span>]);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_60_0.png" alt="png"></p>
<h3 id="Feature-Capital-Gain"><a href="#Feature-Capital-Gain" class="headerlink" title="Feature: Capital Gain"></a>Feature: Capital Gain</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s use the Pandas Cut function to bin the data in equally sized buckets</span></span><br><span class="line">dataset_bin[<span class="string">&#x27;capital-gain&#x27;</span>] = pd.cut(dataset_raw[<span class="string">&#x27;capital-gain&#x27;</span>], <span class="number">5</span>)</span><br><span class="line">dataset_con[<span class="string">&#x27;capital-gain&#x27;</span>] = dataset_raw[<span class="string">&#x27;capital-gain&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">3</span>)) </span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.countplot(y=<span class="string">&quot;capital-gain&quot;</span>, data=dataset_bin);</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.distplot(dataset_con[<span class="string">&#x27;capital-gain&#x27;</span>]);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_62_0.png" alt="png"></p>
<h3 id="Feature-Capital-Loss"><a href="#Feature-Capital-Loss" class="headerlink" title="Feature: Capital Loss"></a>Feature: Capital Loss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s use the Pandas Cut function to bin the data in equally sized buckets</span></span><br><span class="line">dataset_bin[<span class="string">&#x27;capital-loss&#x27;</span>] = pd.cut(dataset_raw[<span class="string">&#x27;capital-loss&#x27;</span>], <span class="number">5</span>)</span><br><span class="line">dataset_con[<span class="string">&#x27;capital-loss&#x27;</span>] = dataset_raw[<span class="string">&#x27;capital-loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">3</span>)) </span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.countplot(y=<span class="string">&quot;capital-loss&quot;</span>, data=dataset_bin);</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.distplot(dataset_con[<span class="string">&#x27;capital-loss&#x27;</span>]);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_64_0.png" alt="png"></p>
<h3 id="Features-Race-Sex-Relationship"><a href="#Features-Race-Sex-Relationship" class="headerlink" title="Features: Race, Sex, Relationship"></a>Features: Race, Sex, Relationship</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Some features we&#x27;ll consider to be in good enough shape as to pass through</span></span><br><span class="line">dataset_con[<span class="string">&#x27;sex&#x27;</span>] = dataset_bin[<span class="string">&#x27;sex&#x27;</span>] = dataset_raw[<span class="string">&#x27;sex&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;race&#x27;</span>] = dataset_bin[<span class="string">&#x27;race&#x27;</span>] = dataset_raw[<span class="string">&#x27;race&#x27;</span>]</span><br><span class="line">dataset_con[<span class="string">&#x27;relationship&#x27;</span>] = dataset_bin[<span class="string">&#x27;relationship&#x27;</span>] = dataset_raw[<span class="string">&#x27;relationship&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h2 id="Bi-variate-Analysis"><a href="#Bi-variate-Analysis" class="headerlink" title="Bi-variate Analysis"></a>Bi-variate Analysis</h2><p>So far, we have analised all features individually. Let’s now start combining some of these features together to obtain further insight into the interactions between them.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot a count of the categories from each categorical feature split by our prediction class: salary - predclass.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_bivariate_bar</span>(<span class="params">dataset, hue, cols=<span class="number">5</span>, width=<span class="number">20</span>, height=<span class="number">15</span>, hspace=<span class="number">0.2</span>, wspace=<span class="number">0.5</span></span>):</span></span><br><span class="line">    dataset = dataset.select_dtypes(include=[np.object])</span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">    fig = plt.figure(figsize=(width,height))</span><br><span class="line">    fig.subplots_adjust(left=<span class="literal">None</span>, bottom=<span class="literal">None</span>, right=<span class="literal">None</span>, top=<span class="literal">None</span>, wspace=wspace, hspace=hspace)</span><br><span class="line">    rows = math.ceil(float(dataset.shape[<span class="number">1</span>]) / cols)</span><br><span class="line">    <span class="keyword">for</span> i, column <span class="keyword">in</span> enumerate(dataset.columns):</span><br><span class="line">        ax = fig.add_subplot(rows, cols, i + <span class="number">1</span>)</span><br><span class="line">        ax.set_title(column)</span><br><span class="line">        <span class="keyword">if</span> dataset.dtypes[column] == np.object:</span><br><span class="line">            g = sns.countplot(y=column, hue=hue, data=dataset)</span><br><span class="line">            substrings = [s.get_text()[:<span class="number">10</span>] <span class="keyword">for</span> s <span class="keyword">in</span> g.get_yticklabels()]</span><br><span class="line">            g.set(yticklabels=substrings)</span><br><span class="line">            </span><br><span class="line">plot_bivariate_bar(dataset_con, hue=<span class="string">&#x27;predclass&#x27;</span>, cols=<span class="number">3</span>, width=<span class="number">20</span>, height=<span class="number">12</span>, hspace=<span class="number">0.4</span>, wspace=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_68_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Effect of Marital Status and Education on Income, across Marital Status.</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">g = sns.FacetGrid(dataset_con, col=<span class="string">&#x27;marital-status&#x27;</span>, size=<span class="number">4</span>, aspect=<span class="number">.7</span>)</span><br><span class="line">g = g.map(sns.boxplot, <span class="string">&#x27;predclass&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_69_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Historical Trends on the Sex, Education, HPW and Age impact on Income.</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">4</span>)) </span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">sns.violinplot(x=<span class="string">&#x27;sex&#x27;</span>, y=<span class="string">&#x27;education-num&#x27;</span>, hue=<span class="string">&#x27;predclass&#x27;</span>, data=dataset_con, split=<span class="literal">True</span>, scale=<span class="string">&#x27;count&#x27;</span>);</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">sns.violinplot(x=<span class="string">&#x27;sex&#x27;</span>, y=<span class="string">&#x27;hours-per-week&#x27;</span>, hue=<span class="string">&#x27;predclass&#x27;</span>, data=dataset_con, split=<span class="literal">True</span>, scale=<span class="string">&#x27;count&#x27;</span>);</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">sns.violinplot(x=<span class="string">&#x27;sex&#x27;</span>, y=<span class="string">&#x27;age&#x27;</span>, hue=<span class="string">&#x27;predclass&#x27;</span>, data=dataset_con, split=<span class="literal">True</span>, scale=<span class="string">&#x27;count&#x27;</span>);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_70_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Interaction between pairs of features.</span></span><br><span class="line">sns.pairplot(dataset_con[[<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;education-num&#x27;</span>,<span class="string">&#x27;hours-per-week&#x27;</span>,<span class="string">&#x27;predclass&#x27;</span>,<span class="string">&#x27;capital-gain&#x27;</span>,<span class="string">&#x27;capital-loss&#x27;</span>]], </span><br><span class="line">             hue=<span class="string">&quot;predclass&quot;</span>, </span><br><span class="line">             diag_kind=<span class="string">&quot;kde&quot;</span>,</span><br><span class="line">             size=<span class="number">4</span>);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_71_0.png" alt="png"></p>
<h2 id="Feature-Crossing-Age-Hours-Per-Week"><a href="#Feature-Crossing-Age-Hours-Per-Week" class="headerlink" title="Feature Crossing: Age + Hours Per Week"></a>Feature Crossing: Age + Hours Per Week</h2><p>So far, we have modified and cleaned features that existed in our dataset. However, we can go further and create a new new variables, adding human knowledge on the interaction between features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Crossing Numerical Features</span></span><br><span class="line">dataset_con[<span class="string">&#x27;age-hours&#x27;</span>] = dataset_con[<span class="string">&#x27;age&#x27;</span>] * dataset_con[<span class="string">&#x27;hours-per-week&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dataset_bin[<span class="string">&#x27;age-hours&#x27;</span>] = pd.cut(dataset_con[<span class="string">&#x27;age-hours&#x27;</span>], <span class="number">10</span>)</span><br><span class="line">dataset_con[<span class="string">&#x27;age-hours&#x27;</span>] = dataset_con[<span class="string">&#x27;age-hours&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>)) </span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.countplot(y=<span class="string">&quot;age-hours&quot;</span>, data=dataset_bin);</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.distplot(dataset_con.loc[dataset_con[<span class="string">&#x27;predclass&#x27;</span>] == <span class="number">1</span>][<span class="string">&#x27;age-hours&#x27;</span>], kde_kws=&#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;&gt;$50K&quot;</span>&#125;);</span><br><span class="line">sns.distplot(dataset_con.loc[dataset_con[<span class="string">&#x27;predclass&#x27;</span>] == <span class="number">0</span>][<span class="string">&#x27;age-hours&#x27;</span>], kde_kws=&#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;&lt;$50K&quot;</span>&#125;);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_73_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Crossing Categorical Features</span></span><br><span class="line">dataset_bin[<span class="string">&#x27;sex-marital&#x27;</span>] = dataset_con[<span class="string">&#x27;sex-marital&#x27;</span>] = dataset_con[<span class="string">&#x27;sex&#x27;</span>] + dataset_con[<span class="string">&#x27;marital-status&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>)) </span><br><span class="line">sns.countplot(y=<span class="string">&quot;sex-marital&quot;</span>, data=dataset_bin);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_74_0.png" alt="png"></p>
<h2 id="Feature-Encoding"><a href="#Feature-Encoding" class="headerlink" title="Feature Encoding"></a>Feature Encoding</h2><p>Remember that Machine Learning algorithms perform Linear Algebra on Matrices, which means all features need have numeric values. The process of converting Categorical Features into values is called Encoding. </p>
<p>Here only perform One-Hot but not Label encoding.</p>
<p>Additional Resources: <a target="_blank" rel="noopener" href="http://pbpython.com/categorical-encoding.html">http://pbpython.com/categorical-encoding.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># One Hot Encodes all labels before Machine Learning</span></span><br><span class="line">one_hot_cols = dataset_bin.columns.tolist()</span><br><span class="line">one_hot_cols.remove(<span class="string">&#x27;predclass&#x27;</span>)</span><br><span class="line">dataset_bin_enc = pd.get_dummies(dataset_bin, columns=one_hot_cols)</span><br><span class="line"></span><br><span class="line">dataset_bin_enc.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predclass</th>
      <th>age_(16.927, 24.3]</th>
      <th>age_(24.3, 31.6]</th>
      <th>age_(31.6, 38.9]</th>
      <th>age_(38.9, 46.2]</th>
      <th>age_(46.2, 53.5]</th>
      <th>age_(53.5, 60.8]</th>
      <th>age_(60.8, 68.1]</th>
      <th>age_(68.1, 75.4]</th>
      <th>age_(75.4, 82.7]</th>
      <th>...</th>
      <th>sex-marital_FemaleMarried</th>
      <th>sex-marital_FemaleNever-Married</th>
      <th>sex-marital_FemaleNot-Married</th>
      <th>sex-marital_FemaleSeparated</th>
      <th>sex-marital_FemaleWidowed</th>
      <th>sex-marital_MaleMarried</th>
      <th>sex-marital_MaleNever-Married</th>
      <th>sex-marital_MaleNot-Married</th>
      <th>sex-marital_MaleSeparated</th>
      <th>sex-marital_MaleWidowed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 116 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;dataset_con&#x27; is original input dataset for this section</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build a new dataframe containing only the object columns</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#obj_df = dataset_con.select_dtypes(include=[&#x27;object&#x27;]).copy()</span></span><br><span class="line"><span class="comment">#obj_df.head()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># use dropna() delete NaN rows</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#obj_df = obj_df.dropna(axis=0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># use most prevailing value to fill in the null values</span></span><br><span class="line"><span class="comment"># (Private -&gt; NaN workclass)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#obj_df[obj_df.isnull().any(axis=1)]</span></span><br><span class="line"><span class="comment">#obj_df[&quot;workclass&quot;].value_counts()</span></span><br><span class="line"><span class="comment">#obj_df = obj_df.fillna(&#123;&quot;workclass&quot;: &quot;Private&quot;&#125;)</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#dataset_con.dtypes</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># delete the rows contains NaN values</span></span><br><span class="line">dataset_con_enc = dataset_con.dropna(axis=<span class="number">0</span>)</span><br><span class="line">print(dataset_con_enc)</span><br><span class="line">dataset_con_enc[dataset_con_enc.isnull().any(axis=<span class="number">1</span>)]</span><br></pre></td></tr></table></figure>

<pre><code>      predclass  age    workclass     occupation native-country  education  \
0             0   39  Non-fed-gov          Admin  United-States  Bachelors   
1             0   50     Self-emp  Office Labour  United-States  Bachelors   
2             0   38      Private  Manual Labour  United-States    HS-grad   
3             0   53      Private  Manual Labour  United-States    Dropout   
4             0   28      Private   Professional  South-America  Bachelors   
...         ...  ...          ...            ...            ...        ...   
48836         0   33      Private   Professional  United-States  Bachelors   
48837         0   39      Private   Professional  United-States  Bachelors   
48839         0   38      Private   Professional  United-States  Bachelors   
48840         0   44      Private          Admin  United-States  Bachelors   
48841         1   35     Self-emp  Office Labour  United-States  Bachelors   

      marital-status  fnlwgt  education-num  hours-per-week  capital-gain  \
0      Never-Married   77516             13              40          2174   
1            Married   83311             13              13             0   
2          Separated  215646              9              40             0   
3            Married  234721              7              40             0   
4            Married  338409             13              40             0   
...              ...     ...            ...             ...           ...   
48836  Never-Married  245211             13              40             0   
48837      Separated  215419             13              36             0   
48839        Married  374983             13              50             0   
48840      Separated   83891             13              40          5455   
48841        Married  182148             13              60             0   

       capital-loss     sex                race   relationship  age-hours  \
0                 0    Male               White  Not-in-family       1560   
1                 0    Male               White        Husband        650   
2                 0    Male               White  Not-in-family       1520   
3                 0    Male               Black        Husband       2120   
4                 0  Female               Black           Wife       1120   
...             ...     ...                 ...            ...        ...   
48836             0    Male               White      Own-child       1320   
48837             0  Female               White  Not-in-family       1404   
48839             0    Male               White        Husband       1900   
48840             0    Male  Asian-Pac-Islander      Own-child       1760   
48841             0    Male               White        Husband       2100   

             sex-marital  
0      MaleNever-Married  
1            MaleMarried  
2          MaleSeparated  
3            MaleMarried  
4          FemaleMarried  
...                  ...  
48836  MaleNever-Married  
48837    FemaleSeparated  
48839        MaleMarried  
48840      MaleSeparated  
48841        MaleMarried  

[45222 rows x 17 columns]</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predclass</th>
      <th>age</th>
      <th>workclass</th>
      <th>occupation</th>
      <th>native-country</th>
      <th>education</th>
      <th>marital-status</th>
      <th>fnlwgt</th>
      <th>education-num</th>
      <th>hours-per-week</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>sex</th>
      <th>race</th>
      <th>relationship</th>
      <th>age-hours</th>
      <th>sex-marital</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Label Encode all labels</span></span><br><span class="line">le = preprocessing.LabelEncoder()</span><br><span class="line">dataset_con_enc = dataset_con_enc.apply(le.fit_transform)</span><br><span class="line"></span><br><span class="line">dataset_con_enc.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predclass</th>
      <th>age</th>
      <th>workclass</th>
      <th>occupation</th>
      <th>native-country</th>
      <th>education</th>
      <th>marital-status</th>
      <th>fnlwgt</th>
      <th>education-num</th>
      <th>hours-per-week</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>sex</th>
      <th>race</th>
      <th>relationship</th>
      <th>age-hours</th>
      <th>sex-marital</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>22</td>
      <td>1</td>
      <td>0</td>
      <td>7</td>
      <td>1</td>
      <td>1</td>
      <td>3217</td>
      <td>12</td>
      <td>39</td>
      <td>26</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>655</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>33</td>
      <td>4</td>
      <td>3</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>3519</td>
      <td>12</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>302</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>21</td>
      <td>3</td>
      <td>1</td>
      <td>7</td>
      <td>5</td>
      <td>3</td>
      <td>17196</td>
      <td>8</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>644</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>36</td>
      <td>3</td>
      <td>1</td>
      <td>7</td>
      <td>3</td>
      <td>0</td>
      <td>18738</td>
      <td>6</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>847</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>11</td>
      <td>3</td>
      <td>4</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>23828</td>
      <td>12</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>5</td>
      <td>494</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="Feature-Reduction-Selection"><a href="#Feature-Reduction-Selection" class="headerlink" title="Feature Reduction / Selection"></a>Feature Reduction / Selection</h2><p>Once we have our features ready to use, we might find that the number of features available is too large to be run in a reasonable timeframe by our machine learning algorithms. There’s a number of options available to us for feature reduction and feature selection.</p>
<ul>
<li><strong>Dimensionality Reduction:</strong><ul>
<li><strong>Principal Component Analysis (PCA):</strong> Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components.</li>
<li><strong>Singular Value Decomposition (SVD):</strong> SVD is a factorization of a real or complex matrix. It is the generalization of the eigendecomposition of a positive semidefinite normal matrix (for example, a symmetric matrix with positive eigenvalues) to any m×n  matrix via an extension of the polar decomposition. It has many useful applications in signal processing and statistics.</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Feature Importance/Relevance:</strong><ul>
<li><strong>Filter Methods:</strong> Filter type methods select features based only on general metrics like the correlation with the variable to predict. Filter methods suppress the least interesting variables. The other variables will be part of a classification or a regression model used to classify or to predict data. These methods are particularly effective in computation time and robust to overfitting.</li>
<li><strong>Wrapper Methods:</strong> Wrapper methods evaluate subsets of variables which allows, unlike filter approaches, to detect the possible interactions between variables. The two main disadvantages of these methods are : The increasing overfitting risk when the number of observations is insufficient. AND. The significant computation time when the number of variables is large.</li>
<li><strong>Embedded Methods:</strong> Embedded methods try to combine the advantages of both previous methods. A learning algorithm takes advantage of its own variable selection process and performs feature selection and classification simultaneously.</li>
</ul>
</li>
</ul>
<h3 id="Feature-Correlation"><a href="#Feature-Correlation" class="headerlink" title="Feature Correlation"></a>Feature Correlation</h3><p>Correlation ia s measure of how much two random variables change together. Features should be uncorrelated with each other and highly correlated to the feature we’re trying to predict.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a correlation plot of both datasets.</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">25</span>,<span class="number">10</span>)) </span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># Generate a mask for the upper triangle</span></span><br><span class="line">mask = np.zeros_like(dataset_bin_enc.corr(), dtype=np.bool)</span><br><span class="line">mask[np.triu_indices_from(mask)] = <span class="literal">True</span></span><br><span class="line">sns.heatmap(dataset_bin_enc.corr(), </span><br><span class="line">            vmin=<span class="number">-1</span>, vmax=<span class="number">1</span>, </span><br><span class="line">            square=<span class="literal">True</span>, </span><br><span class="line">            cmap=sns.color_palette(<span class="string">&quot;RdBu_r&quot;</span>, <span class="number">100</span>), </span><br><span class="line">            mask=mask, </span><br><span class="line">            linewidths=<span class="number">.5</span>);</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">mask = np.zeros_like(dataset_con_enc.corr(), dtype=np.bool)</span><br><span class="line">mask[np.triu_indices_from(mask)] = <span class="literal">True</span></span><br><span class="line">sns.heatmap(dataset_con_enc.corr(), </span><br><span class="line">            vmin=<span class="number">-1</span>, vmax=<span class="number">1</span>, </span><br><span class="line">            square=<span class="literal">True</span>, </span><br><span class="line">            cmap=sns.color_palette(<span class="string">&quot;RdBu_r&quot;</span>, <span class="number">100</span>), </span><br><span class="line">            mask=mask, </span><br><span class="line">            linewidths=<span class="number">.5</span>);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_83_0.png" alt="png"></p>
<h3 id="Feature-Importance"><a href="#Feature-Importance" class="headerlink" title="Feature Importance"></a>Feature Importance</h3><p>Random forest consists of a number of decision trees. Every node in the decision trees is a condition on a single feature, designed to split the dataset into two so that similar response values end up in the same set. The measure based on which the (locally) optimal condition is chosen is called impurity. When training a tree, it can be computed how much each feature decreases the weighted impurity in a tree. For a forest, the impurity decrease from each feature can be averaged and the features are ranked according to this measure. This is the feature importance measure exposed in sklearn’s Random Forest implementations.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Using Random Forest to gain an insight on Feature Importance</span></span><br><span class="line">clf = RandomForestClassifier()</span><br><span class="line">clf.fit(dataset_con_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>), dataset_con_enc[<span class="string">&#x27;predclass&#x27;</span>])</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">importance = clf.feature_importances_</span><br><span class="line">importance = pd.DataFrame(importance, index=dataset_con_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>).columns, columns=[<span class="string">&quot;Importance&quot;</span>])</span><br><span class="line">importance.sort_values(by=<span class="string">&#x27;Importance&#x27;</span>, ascending=<span class="literal">True</span>).plot(kind=<span class="string">&#x27;barh&#x27;</span>, figsize=(<span class="number">20</span>,len(importance)/<span class="number">2</span>));</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_85_0.png" alt="png"></p>
<h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p>Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components.</p>
<p>We can use PCA to reduce the number of features to use in our ML algorithms, and graphing the variance gives us an idea of how many features we really need to represent our dataset fully.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Calculating PCA for both datasets, and graphing the Variance for each feature, per dataset</span></span><br><span class="line">std_scale = preprocessing.StandardScaler().fit(dataset_bin_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>))</span><br><span class="line">X = std_scale.transform(dataset_bin_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>))</span><br><span class="line">pca1 = PCA(n_components=len(dataset_bin_enc.columns)<span class="number">-1</span>)</span><br><span class="line">fit1 = pca1.fit(X)</span><br><span class="line"></span><br><span class="line">std_scale = preprocessing.StandardScaler().fit(dataset_con_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>))</span><br><span class="line">X = std_scale.transform(dataset_con_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>))</span><br><span class="line">pca2 = PCA(n_components=len(dataset_con_enc.columns)<span class="number">-2</span>)</span><br><span class="line">fit2 = pca2.fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Graphing the variance per feature</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">25</span>,<span class="number">7</span>)) </span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;PCA Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Variance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;PCA for Discretised Dataset&#x27;</span>)</span><br><span class="line">plt.bar(range(<span class="number">0</span>, fit1.explained_variance_ratio_.size), fit1.explained_variance_ratio_);</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;PCA Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Variance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;PCA for Continuous Dataset&#x27;</span>)</span><br><span class="line">plt.bar(range(<span class="number">0</span>, fit2.explained_variance_ratio_.size), fit2.explained_variance_ratio_);</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_87_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PCA&#x27;s components graphed in 2D and 3D</span></span><br><span class="line"><span class="comment"># Apply Scaling </span></span><br><span class="line">std_scale = preprocessing.StandardScaler().fit(dataset_con_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>))</span><br><span class="line">X = std_scale.transform(dataset_con_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>))</span><br><span class="line">y = dataset_con_enc[<span class="string">&#x27;predclass&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Formatting</span></span><br><span class="line">target_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">colors = [<span class="string">&#x27;navy&#x27;</span>,<span class="string">&#x27;darkorange&#x27;</span>]</span><br><span class="line">lw = <span class="number">2</span></span><br><span class="line">alpha = <span class="number">0.3</span></span><br><span class="line"><span class="comment"># 2 Components PCA</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">plt.figure(<span class="number">2</span>, figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X_r = pca.fit(X).transform(X)</span><br><span class="line"><span class="keyword">for</span> color, i, target_name <span class="keyword">in</span> zip(colors, [<span class="number">0</span>, <span class="number">1</span>], target_names):</span><br><span class="line">    plt.scatter(X_r[y == i, <span class="number">0</span>], X_r[y == i, <span class="number">1</span>], </span><br><span class="line">                color=color, </span><br><span class="line">                alpha=alpha, </span><br><span class="line">                lw=lw,</span><br><span class="line">                label=target_name)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>, shadow=<span class="literal">False</span>, scatterpoints=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;First two PCA directions&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 Components PCA</span></span><br><span class="line">ax = plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">3</span>)</span><br><span class="line">X_reduced = pca.fit(X).transform(X)</span><br><span class="line"><span class="keyword">for</span> color, i, target_name <span class="keyword">in</span> zip(colors, [<span class="number">0</span>, <span class="number">1</span>], target_names):</span><br><span class="line">    ax.scatter(X_reduced[y == i, <span class="number">0</span>], X_reduced[y == i, <span class="number">1</span>], X_reduced[y == i, <span class="number">2</span>], </span><br><span class="line">               color=color,</span><br><span class="line">               alpha=alpha,</span><br><span class="line">               lw=lw, </span><br><span class="line">               label=target_name)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>, shadow=<span class="literal">False</span>, scatterpoints=<span class="number">1</span>)</span><br><span class="line">ax.set_title(<span class="string">&quot;First three PCA directions&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;1st eigenvector&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;2nd eigenvector&quot;</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&quot;3rd eigenvector&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># rotate the axes</span></span><br><span class="line">ax.view_init(<span class="number">30</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_88_0.png" alt="png"></p>
<h3 id="Recursive-Feature-Elimination"><a href="#Recursive-Feature-Elimination" class="headerlink" title="Recursive Feature Elimination"></a>Recursive Feature Elimination</h3><p>Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Calculating RFE for non-discretised dataset, and graphing the Importance for each feature, per dataset</span></span><br><span class="line">selector1 = RFECV(LogisticRegression(), step=<span class="number">1</span>, cv=<span class="number">5</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">selector1 = selector1.fit(dataset_con_enc.drop(<span class="string">&#x27;predclass&#x27;</span>, axis=<span class="number">1</span>).values, dataset_con_enc[<span class="string">&#x27;predclass&#x27;</span>].values)</span><br><span class="line">print(<span class="string">&quot;Feature Ranking For Non-Discretised: %s&quot;</span> % selector1.ranking_)</span><br><span class="line">print(<span class="string">&quot;Optimal number of features : %d&quot;</span> % selector1.n_features_)</span><br><span class="line"><span class="comment"># Plot number of features VS. cross-validation scores</span></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>)) </span><br><span class="line">plt.xlabel(<span class="string">&quot;Number of features selected - Non-Discretised&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Cross validation score (nb of correct classifications)&quot;</span>)</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(selector1.grid_scores_) + <span class="number">1</span>), selector1.grid_scores_);</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature space could be subsetted like so:</span></span><br><span class="line">dataset_con_enc = dataset_con_enc[dataset_con_enc.columns[np.insert(selector1.support_, <span class="number">0</span>, <span class="literal">True</span>)]]</span><br></pre></td></tr></table></figure>

<pre><code>Feature Ranking For Non-Discretised: [1 1 1 1 3 1 4 1 1 1 1 1 1 1 2 1]
Optimal number of features : 13</code></pre>
<p><img src="/2020/10/08/Census%20Income%20Dataset/output_90_1.png" alt="png"></p>
<h2 id="Selecting-Dataset"><a href="#Selecting-Dataset" class="headerlink" title="Selecting Dataset"></a>Selecting Dataset</h2><p>We now have two datasets to choose from to apply our ML algorithms. The one-hot-encoded, and the label-encoded. For now, we have decided not to use feature reduction or selection algorithms.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># OPTIONS: </span></span><br><span class="line"><span class="comment"># - dataset_bin_enc</span></span><br><span class="line"><span class="comment"># - dataset_con_enc</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the dataset to test how would the algorithms perform under a differently encoded dataset.</span></span><br><span class="line"></span><br><span class="line">selected_dataset = dataset_bin_enc</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">selected_dataset.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predclass</th>
      <th>age_(16.927, 24.3]</th>
      <th>age_(24.3, 31.6]</th>
      <th>age_(31.6, 38.9]</th>
      <th>age_(38.9, 46.2]</th>
      <th>age_(46.2, 53.5]</th>
      <th>age_(53.5, 60.8]</th>
      <th>age_(60.8, 68.1]</th>
      <th>age_(68.1, 75.4]</th>
      <th>age_(75.4, 82.7]</th>
      <th>...</th>
      <th>sex-marital_FemaleMarried</th>
      <th>sex-marital_FemaleNever-Married</th>
      <th>sex-marital_FemaleNot-Married</th>
      <th>sex-marital_FemaleSeparated</th>
      <th>sex-marital_FemaleWidowed</th>
      <th>sex-marital_MaleMarried</th>
      <th>sex-marital_MaleNever-Married</th>
      <th>sex-marital_MaleNot-Married</th>
      <th>sex-marital_MaleSeparated</th>
      <th>sex-marital_MaleWidowed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 116 columns</p>
</div>



<h2 id="Splitting-Data-into-Training-and-Testing-Datasets"><a href="#Splitting-Data-into-Training-and-Testing-Datasets" class="headerlink" title="Splitting Data into Training and Testing Datasets"></a>Splitting Data into Training and Testing Datasets</h2><p>We need to split the data back into the training and testing datasets. Remember we joined both right at the beginning.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Splitting the Training and Test data sets</span></span><br><span class="line">train = selected_dataset.loc[<span class="number">0</span>:<span class="number">32560</span>,:]</span><br><span class="line">test = selected_dataset.loc[<span class="number">32560</span>:,:]</span><br></pre></td></tr></table></figure>

<h3 id="Removing-Samples-with-Missing-data"><a href="#Removing-Samples-with-Missing-data" class="headerlink" title="Removing Samples with Missing data"></a>Removing Samples with Missing data</h3><p>We could have removed rows with missing data during feature cleaning, but we’re choosing to do it at this point. It’s easier to do it this way, right after we split the data into Training and Testing. Otherwise we would have had to keep track of the number of deleted rows in our data and take that into account when deciding on a splitting boundary for our joined data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Given missing fields are a small percentange of the overall dataset, </span></span><br><span class="line"><span class="comment"># we have chosen to delete them.</span></span><br><span class="line">train = train.dropna(axis=<span class="number">0</span>)</span><br><span class="line">test = test.dropna(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Rename-datasets-before-Machine-Learning-algos"><a href="#Rename-datasets-before-Machine-Learning-algos" class="headerlink" title="Rename datasets before Machine Learning algos"></a>Rename datasets before Machine Learning algos</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_train_w_label = train</span><br><span class="line">X_train = train.drop([<span class="string">&#x27;predclass&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y_train = train[<span class="string">&#x27;predclass&#x27;</span>].astype(<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line">X_test  = test.drop([<span class="string">&#x27;predclass&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y_test  = test[<span class="string">&#x27;predclass&#x27;</span>].astype(<span class="string">&#x27;int64&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Machine-Learning-Algorithms"><a href="#Machine-Learning-Algorithms" class="headerlink" title="Machine Learning Algorithms"></a>Machine Learning Algorithms</h2><h3 id="Data-Review"><a href="#Data-Review" class="headerlink" title="Data Review"></a>Data Review</h3><p>Let’s take one last peek at our data before we start running the Machine Learning algorithms.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train.shape</span><br></pre></td></tr></table></figure>




<pre><code>(32561, 115)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age_(16.927, 24.3]</th>
      <th>age_(24.3, 31.6]</th>
      <th>age_(31.6, 38.9]</th>
      <th>age_(38.9, 46.2]</th>
      <th>age_(46.2, 53.5]</th>
      <th>age_(53.5, 60.8]</th>
      <th>age_(60.8, 68.1]</th>
      <th>age_(68.1, 75.4]</th>
      <th>age_(75.4, 82.7]</th>
      <th>age_(82.7, 90.0]</th>
      <th>...</th>
      <th>sex-marital_FemaleMarried</th>
      <th>sex-marital_FemaleNever-Married</th>
      <th>sex-marital_FemaleNot-Married</th>
      <th>sex-marital_FemaleSeparated</th>
      <th>sex-marital_FemaleWidowed</th>
      <th>sex-marital_MaleMarried</th>
      <th>sex-marital_MaleNever-Married</th>
      <th>sex-marital_MaleNot-Married</th>
      <th>sex-marital_MaleSeparated</th>
      <th>sex-marital_MaleWidowed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 115 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train.head()</span><br></pre></td></tr></table></figure>




<pre><code>0    0
1    0
2    0
3    0
4    0
Name: predclass, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setting a random seed will guarantee we get the same results </span></span><br><span class="line"><span class="comment"># every time we run our training and testing.</span></span><br><span class="line">random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h3><p>From here, we will be running the following algorithms.</p>
<ul>
<li>KNN</li>
<li>Logistic Regression</li>
<li>Random Forest</li>
<li>Naive Bayes</li>
<li>Stochastic Gradient Decent</li>
<li>Linear SVC</li>
<li>Decision Tree</li>
<li>Gradient Boosted Trees</li>
</ul>
<p>Because there’s a great deal of repetitiveness on the code for each, we’ll create a custom function to analyse this.</p>
<p>For some algorithms, we have also chosen to run a Random Hyperparameter search, to select the best hyperparameters for a given algorithm.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculate the fpr and tpr for all thresholds of the classification</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_roc_curve</span>(<span class="params">y_test, preds</span>):</span></span><br><span class="line">    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)</span><br><span class="line">    roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">    plt.title(<span class="string">&#x27;Receiver Operating Characteristic&#x27;</span>)</span><br><span class="line">    plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label = <span class="string">&#x27;AUC = %0.2f&#x27;</span> % roc_auc)</span><br><span class="line">    plt.legend(loc = <span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>],<span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">    plt.xlim([<span class="number">-0.01</span>, <span class="number">1.01</span>])</span><br><span class="line">    plt.ylim([<span class="number">-0.01</span>, <span class="number">1.01</span>])</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Function that runs the requested algorithm and returns the accuracy metrics</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_ml_algo</span>(<span class="params">algo, X_train, y_train, X_test, cv</span>):</span></span><br><span class="line">    <span class="comment"># One Pass</span></span><br><span class="line">    model = algo.fit(X_train, y_train)</span><br><span class="line">    test_pred = model.predict(X_test)</span><br><span class="line">    <span class="keyword">if</span> (isinstance(algo, (LogisticRegression, </span><br><span class="line">                          KNeighborsClassifier, </span><br><span class="line">                          GaussianNB, </span><br><span class="line">                          DecisionTreeClassifier, </span><br><span class="line">                          RandomForestClassifier,</span><br><span class="line">                          GradientBoostingClassifier))):</span><br><span class="line">        probs = model.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        probs = <span class="string">&quot;Not Available&quot;</span></span><br><span class="line">    acc = round(model.score(X_test, y_test) * <span class="number">100</span>, <span class="number">2</span>) </span><br><span class="line">    <span class="comment"># CV </span></span><br><span class="line">    train_pred = model_selection.cross_val_predict(algo, </span><br><span class="line">                                                  X_train, </span><br><span class="line">                                                  y_train, </span><br><span class="line">                                                  cv=cv, </span><br><span class="line">                                                  n_jobs = <span class="number">-1</span>)</span><br><span class="line">    acc_cv = round(metrics.accuracy_score(y_train, train_pred) * <span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> train_pred, test_pred, acc, acc_cv, probs</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Logistic Regression - Random Search for Hyperparameters</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Utility function to report best scores</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">report</span>(<span class="params">results, n_top=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n_top + <span class="number">1</span>):</span><br><span class="line">        candidates = np.flatnonzero(results[<span class="string">&#x27;rank_test_score&#x27;</span>] == i)</span><br><span class="line">        <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates:</span><br><span class="line">            print(<span class="string">&quot;Model with rank: &#123;0&#125;&quot;</span>.format(i))</span><br><span class="line">            print(<span class="string">&quot;Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)&quot;</span>.format(</span><br><span class="line">                  results[<span class="string">&#x27;mean_test_score&#x27;</span>][candidate],</span><br><span class="line">                  results[<span class="string">&#x27;std_test_score&#x27;</span>][candidate]))</span><br><span class="line">            print(<span class="string">&quot;Parameters: &#123;0&#125;&quot;</span>.format(results[<span class="string">&#x27;params&#x27;</span>][candidate]))</span><br><span class="line">            print(<span class="string">&quot;&quot;</span>)</span><br><span class="line">            </span><br><span class="line"><span class="comment"># Specify parameters and distributions to sample from</span></span><br><span class="line">param_dist = &#123;<span class="string">&#x27;penalty&#x27;</span>: [<span class="string">&#x27;l2&#x27;</span>, <span class="string">&#x27;l1&#x27;</span>], </span><br><span class="line">                         <span class="string">&#x27;class_weight&#x27;</span>: [<span class="literal">None</span>, <span class="string">&#x27;balanced&#x27;</span>],</span><br><span class="line">                         <span class="string">&#x27;C&#x27;</span>: np.logspace(<span class="number">-20</span>, <span class="number">20</span>, <span class="number">10000</span>), </span><br><span class="line">                         <span class="string">&#x27;intercept_scaling&#x27;</span>: np.logspace(<span class="number">-20</span>, <span class="number">20</span>, <span class="number">10000</span>)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run Randomized Search</span></span><br><span class="line">n_iter_search = <span class="number">10</span></span><br><span class="line">lrc = LogisticRegression()</span><br><span class="line">random_search = RandomizedSearchCV(lrc, </span><br><span class="line">                                   n_jobs=<span class="number">-1</span>, </span><br><span class="line">                                   param_distributions=param_dist, </span><br><span class="line">                                   n_iter=n_iter_search)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line">random_search.fit(X_train, y_train)</span><br><span class="line">print(<span class="string">&quot;RandomizedSearchCV took %.2f seconds for %d candidates&quot;</span></span><br><span class="line">      <span class="string">&quot; parameter settings.&quot;</span> % ((time.time() - start), n_iter_search))</span><br><span class="line">report(random_search.cv_results_)</span><br></pre></td></tr></table></figure>

<pre><code>RandomizedSearchCV took 6.84 seconds for 10 candidates parameter settings.
Model with rank: 1
Mean validation score: 0.844 (std: 0.004)
Parameters: &#123;&#39;penalty&#39;: &#39;l2&#39;, &#39;intercept_scaling&#39;: 42370413880.09742, &#39;class_weight&#39;: None, &#39;C&#39;: 6.248554728170629e+17&#125;

Model with rank: 2
Mean validation score: 0.800 (std: 0.004)
Parameters: &#123;&#39;penalty&#39;: &#39;l2&#39;, &#39;intercept_scaling&#39;: 5.356398592977186e-12, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;C&#39;: 318529980510.9508&#125;

Model with rank: 2
Mean validation score: 0.800 (std: 0.004)
Parameters: &#123;&#39;penalty&#39;: &#39;l2&#39;, &#39;intercept_scaling&#39;: 6.741908876164404e-13, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;C&#39;: 1.753171420878381e+18&#125;

Model with rank: 4
Mean validation score: 0.800 (std: 0.004)
Parameters: &#123;&#39;penalty&#39;: &#39;l2&#39;, &#39;intercept_scaling&#39;: 0.03646331805309427, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;C&#39;: 431085.5408791511&#125;

Model with rank: 5
Mean validation score: 0.759 (std: 0.000)
Parameters: &#123;&#39;penalty&#39;: &#39;l2&#39;, &#39;intercept_scaling&#39;: 52853324182.66478, &#39;class_weight&#39;: None, &#39;C&#39;: 3.311707756163145e-20&#125;</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Logistic Regression</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">train_pred_log, test_pred_log, acc_log, acc_cv_log, probs_log = fit_ml_algo(LogisticRegression(n_jobs = <span class="number">-1</span>), </span><br><span class="line">                                                                 X_train, </span><br><span class="line">                                                                 y_train, </span><br><span class="line">                                                                 X_test, </span><br><span class="line">                                                                 <span class="number">10</span>)</span><br><span class="line">log_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_log)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_log)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=log_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 84.47
Accuracy CV 10-Fold: 84.33
Running Time: 0:00:09.857440</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.confusion_matrix(y_test, test_pred_log))</span><br></pre></td></tr></table></figure>

<pre><code>[[11501   934]
 [ 1595  2252]]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_log))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.88      0.93      0.90     24720
           1       0.71      0.58      0.64      7841

    accuracy                           0.84     32561
   macro avg       0.79      0.75      0.77     32561
weighted avg       0.84      0.84      0.84     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_log))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.88      0.92      0.90     12435
           1       0.71      0.59      0.64      3847

    accuracy                           0.84     16282
   macro avg       0.79      0.76      0.77     16282
weighted avg       0.84      0.84      0.84     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_roc_curve(y_test, probs_log)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_114_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k-Nearest Neighbors</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">train_pred_knn, test_pred_knn, acc_knn, acc_cv_knn, probs_knn = fit_ml_algo(KNeighborsClassifier(n_neighbors = <span class="number">3</span>,</span><br><span class="line">                                                                                                 n_jobs = <span class="number">-1</span>), </span><br><span class="line">                                                                                                 X_train, </span><br><span class="line">                                                                                                 y_train, </span><br><span class="line">                                                                                                 X_test, </span><br><span class="line">                                                                                                 <span class="number">10</span>)</span><br><span class="line">knn_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_knn)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_knn)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=knn_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 81.02
Accuracy CV 10-Fold: 81.13
Running Time: 0:02:21.181324</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_knn))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.86      0.89      0.88     24720
           1       0.62      0.56      0.59      7841

    accuracy                           0.81     32561
   macro avg       0.74      0.73      0.73     32561
weighted avg       0.81      0.81      0.81     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_knn))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.87      0.89      0.88     12435
           1       0.61      0.56      0.58      3847

    accuracy                           0.81     16282
   macro avg       0.74      0.72      0.73     16282
weighted avg       0.81      0.81      0.81     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_roc_curve(y_test, probs_knn)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_118_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gaussian Naive Bayes</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">train_pred_gaussian, test_pred_gaussian, acc_gaussian, acc_cv_gaussian, probs_gau = fit_ml_algo(GaussianNB(), </span><br><span class="line">                                                                                     X_train, </span><br><span class="line">                                                                                     y_train, </span><br><span class="line">                                                                                     X_test, </span><br><span class="line">                                                                                     <span class="number">10</span>)</span><br><span class="line">gaussian_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_gaussian)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_gaussian)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=gaussian_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 75.59
Accuracy CV 10-Fold: 74.51
Running Time: 0:00:00.479271</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_gaussian)) </span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.95      0.70      0.81     24720
           1       0.48      0.88      0.62      7841

    accuracy                           0.75     32561
   macro avg       0.72      0.79      0.72     32561
weighted avg       0.84      0.75      0.76     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_gaussian))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.94      0.72      0.82     12435
           1       0.49      0.86      0.63      3847

    accuracy                           0.76     16282
   macro avg       0.72      0.79      0.72     16282
weighted avg       0.84      0.76      0.77     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_roc_curve(y_test, probs_gau)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_122_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Linear SVC</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">train_pred_svc, test_pred_svc, acc_linear_svc, acc_cv_linear_svc, _ = fit_ml_algo(LinearSVC(),</span><br><span class="line">                                                                                           X_train, </span><br><span class="line">                                                                                           y_train,</span><br><span class="line">                                                                                           X_test, </span><br><span class="line">                                                                                           <span class="number">10</span>)</span><br><span class="line">linear_svc_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_linear_svc)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_linear_svc)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=linear_svc_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 84.42
Accuracy CV 10-Fold: 84.46
Running Time: 0:00:07.630441</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_svc))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.88      0.93      0.90     24720
           1       0.72      0.58      0.64      7841

    accuracy                           0.84     32561
   macro avg       0.80      0.76      0.77     32561
weighted avg       0.84      0.84      0.84     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_svc)) </span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.88      0.93      0.90     12435
           1       0.71      0.58      0.64      3847

    accuracy                           0.84     16282
   macro avg       0.79      0.75      0.77     16282
weighted avg       0.84      0.84      0.84     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stochastic Gradient Descent</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">train_pred_sgd, test_pred_sgd, acc_sgd, acc_cv_sgd, _ = fit_ml_algo(SGDClassifier(n_jobs = <span class="number">-1</span>), </span><br><span class="line">                                                                 X_train, </span><br><span class="line">                                                                 y_train, </span><br><span class="line">                                                                 X_test, </span><br><span class="line">                                                                 <span class="number">10</span>)</span><br><span class="line">sgd_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_sgd)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_sgd)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=sgd_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 84.15
Accuracy CV 10-Fold: 83.74
Running Time: 0:00:02.039138</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_sgd))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.88      0.91      0.89     24720
           1       0.69      0.60      0.64      7841

    accuracy                           0.84     32561
   macro avg       0.78      0.76      0.77     32561
weighted avg       0.83      0.84      0.83     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_sgd))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.88      0.91      0.90     12435
           1       0.69      0.61      0.64      3847

    accuracy                           0.84     16282
   macro avg       0.78      0.76      0.77     16282
weighted avg       0.84      0.84      0.84     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Decision Tree Classifier</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">train_pred_dt, test_pred_dt, acc_dt, acc_cv_dt, probs_dt = fit_ml_algo(DecisionTreeClassifier(), </span><br><span class="line">                                                             X_train, </span><br><span class="line">                                                             y_train, </span><br><span class="line">                                                             X_test, </span><br><span class="line">                                                             <span class="number">10</span>)</span><br><span class="line">dt_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_dt)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_dt)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=dt_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 79.93
Accuracy CV 10-Fold: 80.44
Running Time: 0:00:01.417276</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.confusion_matrix(y_test, test_pred_dt))</span><br></pre></td></tr></table></figure>

<pre><code>[[10956  1479]
 [ 1788  2059]]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_dt))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.86      0.89      0.87     24720
           1       0.60      0.54      0.57      7841

    accuracy                           0.80     32561
   macro avg       0.73      0.72      0.72     32561
weighted avg       0.80      0.80      0.80     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_dt))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.86      0.88      0.87     12435
           1       0.58      0.54      0.56      3847

    accuracy                           0.80     16282
   macro avg       0.72      0.71      0.71     16282
weighted avg       0.79      0.80      0.80     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_roc_curve(y_test, probs_dt)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_133_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Random Forest Classifier - Random Search for Hyperparameters</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Utility function to report best scores</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">report</span>(<span class="params">results, n_top=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n_top + <span class="number">1</span>):</span><br><span class="line">        candidates = np.flatnonzero(results[<span class="string">&#x27;rank_test_score&#x27;</span>] == i)</span><br><span class="line">        <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates:</span><br><span class="line">            print(<span class="string">&quot;Model with rank: &#123;0&#125;&quot;</span>.format(i))</span><br><span class="line">            print(<span class="string">&quot;Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)&quot;</span>.format(</span><br><span class="line">                  results[<span class="string">&#x27;mean_test_score&#x27;</span>][candidate],</span><br><span class="line">                  results[<span class="string">&#x27;std_test_score&#x27;</span>][candidate]))</span><br><span class="line">            print(<span class="string">&quot;Parameters: &#123;0&#125;&quot;</span>.format(results[<span class="string">&#x27;params&#x27;</span>][candidate]))</span><br><span class="line">            print(<span class="string">&quot;&quot;</span>)</span><br><span class="line">            </span><br><span class="line"><span class="comment"># Specify parameters and distributions to sample from</span></span><br><span class="line">param_dist = &#123;<span class="string">&quot;max_depth&quot;</span>: [<span class="number">10</span>, <span class="literal">None</span>],</span><br><span class="line">              <span class="string">&quot;max_features&quot;</span>: sp_randint(<span class="number">1</span>, <span class="number">11</span>),</span><br><span class="line">              <span class="string">&quot;min_samples_split&quot;</span>: sp_randint(<span class="number">2</span>, <span class="number">20</span>),</span><br><span class="line">              <span class="string">&quot;min_samples_leaf&quot;</span>: sp_randint(<span class="number">1</span>, <span class="number">11</span>),</span><br><span class="line">              <span class="string">&quot;bootstrap&quot;</span>: [<span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">              <span class="string">&quot;criterion&quot;</span>: [<span class="string">&quot;gini&quot;</span>, <span class="string">&quot;entropy&quot;</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run Randomized Search</span></span><br><span class="line">n_iter_search = <span class="number">10</span></span><br><span class="line">rfc = RandomForestClassifier(n_estimators=<span class="number">10</span>)</span><br><span class="line">random_search = RandomizedSearchCV(rfc, </span><br><span class="line">                                   n_jobs = <span class="number">-1</span>, </span><br><span class="line">                                   param_distributions=param_dist, </span><br><span class="line">                                   n_iter=n_iter_search)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line">random_search.fit(X_train, y_train)</span><br><span class="line">print(<span class="string">&quot;RandomizedSearchCV took %.2f seconds for %d candidates&quot;</span></span><br><span class="line">      <span class="string">&quot; parameter settings.&quot;</span> % ((time.time() - start), n_iter_search))</span><br><span class="line">report(random_search.cv_results_)</span><br></pre></td></tr></table></figure>

<pre><code>RandomizedSearchCV took 2.68 seconds for 10 candidates parameter settings.
Model with rank: 1
Mean validation score: 0.839 (std: 0.004)
Parameters: &#123;&#39;bootstrap&#39;: False, &#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: None, &#39;max_features&#39;: 4, &#39;min_samples_leaf&#39;: 2, &#39;min_samples_split&#39;: 13&#125;

Model with rank: 2
Mean validation score: 0.838 (std: 0.005)
Parameters: &#123;&#39;bootstrap&#39;: True, &#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: None, &#39;max_features&#39;: 10, &#39;min_samples_leaf&#39;: 5, &#39;min_samples_split&#39;: 2&#125;

Model with rank: 3
Mean validation score: 0.838 (std: 0.005)
Parameters: &#123;&#39;bootstrap&#39;: False, &#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: None, &#39;max_features&#39;: 7, &#39;min_samples_leaf&#39;: 9, &#39;min_samples_split&#39;: 4&#125;

Model with rank: 4
Mean validation score: 0.838 (std: 0.004)
Parameters: &#123;&#39;bootstrap&#39;: True, &#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 10, &#39;max_features&#39;: 10, &#39;min_samples_leaf&#39;: 2, &#39;min_samples_split&#39;: 13&#125;

Model with rank: 5
Mean validation score: 0.834 (std: 0.004)
Parameters: &#123;&#39;bootstrap&#39;: False, &#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 10, &#39;max_features&#39;: 7, &#39;min_samples_leaf&#39;: 5, &#39;min_samples_split&#39;: 2&#125;</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Random Forest Classifier</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">rfc = RandomForestClassifier(n_estimators=<span class="number">10</span>, </span><br><span class="line">                             min_samples_leaf=<span class="number">2</span>,</span><br><span class="line">                             min_samples_split=<span class="number">17</span>, </span><br><span class="line">                             criterion=<span class="string">&#x27;gini&#x27;</span>, </span><br><span class="line">                             max_features=<span class="number">8</span>)</span><br><span class="line">train_pred_rf, test_pred_rf, acc_rf, acc_cv_rf, probs_rf = fit_ml_algo(rfc, </span><br><span class="line">                                                             X_train, </span><br><span class="line">                                                             y_train, </span><br><span class="line">                                                             X_test, </span><br><span class="line">                                                             <span class="number">10</span>)</span><br><span class="line">rf_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_rf)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_rf)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=rf_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 84.07
Accuracy CV 10-Fold: 84.05
Running Time: 0:00:01.423032</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_rf))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.87      0.93      0.90     24720
           1       0.71      0.57      0.63      7841

    accuracy                           0.84     32561
   macro avg       0.79      0.75      0.76     32561
weighted avg       0.83      0.84      0.83     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_rf))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.87      0.93      0.90     12435
           1       0.70      0.56      0.63      3847

    accuracy                           0.84     16282
   macro avg       0.79      0.74      0.76     16282
weighted avg       0.83      0.84      0.83     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_roc_curve(y_test, probs_rf)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_138_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gradient Boosting Trees</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">train_pred_gbt, test_pred_gbt, acc_gbt, acc_cv_gbt, probs_gbt = fit_ml_algo(GradientBoostingClassifier(), </span><br><span class="line">                                                                 X_train, </span><br><span class="line">                                                                 y_train, </span><br><span class="line">                                                                 X_test, </span><br><span class="line">                                                                 <span class="number">10</span>)</span><br><span class="line">gbt_time = (time.time() - start_time)</span><br><span class="line">print(<span class="string">&quot;Accuracy: %s&quot;</span> % acc_gbt)</span><br><span class="line">print(<span class="string">&quot;Accuracy CV 10-Fold: %s&quot;</span> % acc_cv_gbt)</span><br><span class="line">print(<span class="string">&quot;Running Time: %s&quot;</span> % datetime.timedelta(seconds=gbt_time))</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 84.53
Accuracy CV 10-Fold: 84.34
Running Time: 0:00:18.993168</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_train, train_pred_gbt))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.87      0.93      0.90     24720
           1       0.72      0.57      0.64      7841

    accuracy                           0.84     32561
   macro avg       0.80      0.75      0.77     32561
weighted avg       0.84      0.84      0.84     32561</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y_test, test_pred_gbt))</span><br></pre></td></tr></table></figure>

<pre><code>              precision    recall  f1-score   support

           0       0.88      0.93      0.90     12435
           1       0.71      0.58      0.64      3847

    accuracy                           0.85     16282
   macro avg       0.79      0.75      0.77     16282
weighted avg       0.84      0.85      0.84     16282</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_roc_curve(y_test, probs_gbt)</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_142_0.png" alt="png"></p>
<h2 id="Ranking-Results"><a href="#Ranking-Results" class="headerlink" title="Ranking Results"></a>Ranking Results</h2><p>Let’s rank the results for all the algorithms we have used</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">models = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: [<span class="string">&#x27;KNN&#x27;</span>, <span class="string">&#x27;Logistic Regression&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;Random Forest&#x27;</span>, <span class="string">&#x27;Naive Bayes&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;Stochastic Gradient Decent&#x27;</span>, <span class="string">&#x27;Linear SVC&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;Decision Tree&#x27;</span>, <span class="string">&#x27;Gradient Boosting Trees&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;Score&#x27;</span>: [</span><br><span class="line">        acc_knn, </span><br><span class="line">        acc_log, </span><br><span class="line">        acc_rf, </span><br><span class="line">        acc_gaussian, </span><br><span class="line">        acc_sgd, </span><br><span class="line">        acc_linear_svc, </span><br><span class="line">        acc_dt,</span><br><span class="line">        acc_gbt</span><br><span class="line">    ]&#125;)</span><br><span class="line">models.sort_values(by=<span class="string">&#x27;Score&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>Gradient Boosting Trees</td>
      <td>84.53</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Logistic Regression</td>
      <td>84.47</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Linear SVC</td>
      <td>84.42</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Stochastic Gradient Decent</td>
      <td>84.15</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Random Forest</td>
      <td>84.07</td>
    </tr>
    <tr>
      <th>0</th>
      <td>KNN</td>
      <td>81.02</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Decision Tree</td>
      <td>79.93</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Naive Bayes</td>
      <td>75.59</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">models = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: [<span class="string">&#x27;KNN&#x27;</span>, <span class="string">&#x27;Logistic Regression&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;Random Forest&#x27;</span>, <span class="string">&#x27;Naive Bayes&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;Stochastic Gradient Decent&#x27;</span>, <span class="string">&#x27;Linear SVC&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;Decision Tree&#x27;</span>, <span class="string">&#x27;Gradient Boosting Trees&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;Score&#x27;</span>: [</span><br><span class="line">        acc_cv_knn, </span><br><span class="line">        acc_cv_log,     </span><br><span class="line">        acc_cv_rf, </span><br><span class="line">        acc_cv_gaussian, </span><br><span class="line">        acc_cv_sgd, </span><br><span class="line">        acc_cv_linear_svc, </span><br><span class="line">        acc_cv_dt,</span><br><span class="line">        acc_cv_gbt</span><br><span class="line">    ]&#125;)</span><br><span class="line">models.sort_values(by=<span class="string">&#x27;Score&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>Linear SVC</td>
      <td>84.46</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Gradient Boosting Trees</td>
      <td>84.34</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Logistic Regression</td>
      <td>84.33</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Random Forest</td>
      <td>84.05</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Stochastic Gradient Decent</td>
      <td>83.74</td>
    </tr>
    <tr>
      <th>0</th>
      <td>KNN</td>
      <td>81.13</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Decision Tree</td>
      <td>80.44</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Naive Bayes</td>
      <td>74.51</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>)) </span><br><span class="line"></span><br><span class="line">models = [</span><br><span class="line">    <span class="string">&#x27;KNN&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;Logistic Regression&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;Random Forest&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;Naive Bayes&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;Decision Tree&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;Gradient Boosting Trees&#x27;</span></span><br><span class="line">]</span><br><span class="line">probs = [</span><br><span class="line">    probs_knn,</span><br><span class="line">    probs_log,</span><br><span class="line">    probs_rf,</span><br><span class="line">    probs_gau,</span><br><span class="line">    probs_dt,</span><br><span class="line">    probs_gbt</span><br><span class="line">]</span><br><span class="line">colors = [</span><br><span class="line">    <span class="string">&#x27;blue&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;green&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cyan&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;magenta&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;yellow&#x27;</span>,</span><br><span class="line">]</span><br><span class="line">    </span><br><span class="line">plt.title(<span class="string">&#x27;Receiver Operating Characteristic&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>],<span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt.xlim([<span class="number">-0.01</span>, <span class="number">1.01</span>])</span><br><span class="line">plt.ylim([<span class="number">-0.01</span>, <span class="number">1.01</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_roc_curves</span>(<span class="params">y_test, prob, model</span>):</span></span><br><span class="line">    fpr, tpr, threshold = metrics.roc_curve(y_test, prob)</span><br><span class="line">    roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">    plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label = model + <span class="string">&#x27; AUC = %0.2f&#x27;</span> % roc_auc, color=colors[i])</span><br><span class="line">    plt.legend(loc = <span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i, model <span class="keyword">in</span> list(enumerate(models)):</span><br><span class="line">    plot_roc_curves(y_test, probs[i], models[i])</span><br><span class="line">    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_146_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>)) </span><br><span class="line"></span><br><span class="line">models = [</span><br><span class="line">    <span class="string">&#x27;Logistic Regression&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;Decision Tree&#x27;</span>, </span><br><span class="line">]</span><br><span class="line">probs = [</span><br><span class="line">    probs_log,  </span><br><span class="line">    probs_dt,</span><br><span class="line">]</span><br><span class="line">colors = [</span><br><span class="line">    <span class="string">&#x27;blue&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;green&#x27;</span>,</span><br><span class="line">]</span><br><span class="line">    </span><br><span class="line">plt.title(<span class="string">&#x27;Receiver Operating Characteristic&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>],<span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt.xlim([<span class="number">-0.01</span>, <span class="number">1.01</span>])</span><br><span class="line">plt.ylim([<span class="number">-0.01</span>, <span class="number">1.01</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_roc_curves</span>(<span class="params">y_test, prob, model</span>):</span></span><br><span class="line">    fpr, tpr, threshold = metrics.roc_curve(y_test, prob)</span><br><span class="line">    roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">    plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label = model + <span class="string">&#x27; AUC = %0.2f&#x27;</span> % roc_auc, color=colors[i])</span><br><span class="line">    plt.legend(loc = <span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i, model <span class="keyword">in</span> list(enumerate(models)):</span><br><span class="line">    plot_roc_curves(y_test, probs[i], models[i])</span><br><span class="line">    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>



<p><img src="/2020/10/08/Census%20Income%20Dataset/output_147_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    
    
      

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>Fan Huang
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="http://muyuhuatang.github.io/2020/10/08/Census%20Income%20Dataset/" title="">http://muyuhuatang.github.io/2020/10/08/Census Income Dataset/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/10/06/SmallTools/" rel="prev" title="Small Tools">
      <i class="fa fa-chevron-left"></i> Small Tools
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="minivaline-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Data-Science-Classification-Analysis"><span class="nav-number">1.</span> <span class="nav-text">Data Science, Classification Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Cleaning-Feature-Engineering-Imputation-and-Classification"><span class="nav-number">1.1.</span> <span class="nav-text">Data Cleaning, Feature Engineering, Imputation, and Classification.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Checking-Number-of-CPU%E2%80%99s-available-to-Docker-container"><span class="nav-number">1.2.</span> <span class="nav-text">Checking Number of CPU’s available to Docker container</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Import-Standard-Python-Libraries"><span class="nav-number">1.3.</span> <span class="nav-text">Import Standard Python Libraries</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Packages-Install"><span class="nav-number">1.4.</span> <span class="nav-text">Packages Install</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Packages-Update"><span class="nav-number">1.5.</span> <span class="nav-text">Packages Update</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Packages-Import"><span class="nav-number">1.6.</span> <span class="nav-text">Packages Import</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Listing-Installed-Packages"><span class="nav-number">1.7.</span> <span class="nav-text">Listing Installed Packages</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Objective"><span class="nav-number">1.8.</span> <span class="nav-text">Objective</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Download-and-Loading"><span class="nav-number">1.9.</span> <span class="nav-text">Data Download and Loading</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Exploration-Univariate"><span class="nav-number">1.10.</span> <span class="nav-text">Data Exploration - Univariate</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Feature-Cleaning-Engineering-and-Imputation"><span class="nav-number">2.</span> <span class="nav-text">Feature Cleaning, Engineering, and Imputation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Predclass"><span class="nav-number">2.0.1.</span> <span class="nav-text">Feature Predclass</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Age"><span class="nav-number">2.0.2.</span> <span class="nav-text">Feature: Age</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Workclass"><span class="nav-number">2.0.3.</span> <span class="nav-text">Feature: Workclass</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Occupation"><span class="nav-number">2.0.4.</span> <span class="nav-text">Feature: Occupation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Native-Country"><span class="nav-number">2.0.5.</span> <span class="nav-text">Feature: Native Country</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Education"><span class="nav-number">2.0.6.</span> <span class="nav-text">Feature: Education</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Marital-Status"><span class="nav-number">2.0.7.</span> <span class="nav-text">Feature: Marital Status</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Final-Weight"><span class="nav-number">2.0.8.</span> <span class="nav-text">Feature: Final Weight</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Education-Number"><span class="nav-number">2.0.9.</span> <span class="nav-text">Feature: Education Number</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Hours-per-Week"><span class="nav-number">2.0.10.</span> <span class="nav-text">Feature: Hours per Week</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Capital-Gain"><span class="nav-number">2.0.11.</span> <span class="nav-text">Feature: Capital Gain</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Capital-Loss"><span class="nav-number">2.0.12.</span> <span class="nav-text">Feature: Capital Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Features-Race-Sex-Relationship"><span class="nav-number">2.0.13.</span> <span class="nav-text">Features: Race, Sex, Relationship</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bi-variate-Analysis"><span class="nav-number">2.1.</span> <span class="nav-text">Bi-variate Analysis</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Feature-Crossing-Age-Hours-Per-Week"><span class="nav-number">2.2.</span> <span class="nav-text">Feature Crossing: Age + Hours Per Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Feature-Encoding"><span class="nav-number">2.3.</span> <span class="nav-text">Feature Encoding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Feature-Reduction-Selection"><span class="nav-number">2.4.</span> <span class="nav-text">Feature Reduction &#x2F; Selection</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Correlation"><span class="nav-number">2.4.1.</span> <span class="nav-text">Feature Correlation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Importance"><span class="nav-number">2.4.2.</span> <span class="nav-text">Feature Importance</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PCA"><span class="nav-number">2.4.3.</span> <span class="nav-text">PCA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Recursive-Feature-Elimination"><span class="nav-number">2.4.4.</span> <span class="nav-text">Recursive Feature Elimination</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Selecting-Dataset"><span class="nav-number">2.5.</span> <span class="nav-text">Selecting Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Splitting-Data-into-Training-and-Testing-Datasets"><span class="nav-number">2.6.</span> <span class="nav-text">Splitting Data into Training and Testing Datasets</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Removing-Samples-with-Missing-data"><span class="nav-number">2.6.1.</span> <span class="nav-text">Removing Samples with Missing data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Rename-datasets-before-Machine-Learning-algos"><span class="nav-number">2.6.2.</span> <span class="nav-text">Rename datasets before Machine Learning algos</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Machine-Learning-Algorithms"><span class="nav-number">2.7.</span> <span class="nav-text">Machine Learning Algorithms</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Review"><span class="nav-number">2.7.1.</span> <span class="nav-text">Data Review</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Algorithms"><span class="nav-number">2.7.2.</span> <span class="nav-text">Algorithms</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ranking-Results"><span class="nav-number">2.8.</span> <span class="nav-text">Ranking Results</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Fan Huang"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Fan Huang</p>
  <div class="site-description" itemprop="description">The blog site of Fan Huang</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/muyuhuatang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;muyuhuatang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fhuang181@gmail.com" title="E-Mail → mailto:fhuang181@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fan Huang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">77k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">56 mins.</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  


<script>
loadComments(document.querySelector('#minivaline-comments'), function(){
	getScript('https://cdn.jsdelivr.net/npm/minivaline@2/dist/MiniValine.min.js', function(){
		new MiniValine({
			el: '#minivaline-comments',
			appId: 'zhM0AOiqle17oPoE84CoYw1e-gzGzoHsz',
			appKey: 'itmzT1JbXfAjVwMqDhGPzU45',
			mode: 'DesertsP',
			placeholder: 'Write a Comment',
			pathname: '/2020/10/08/Census Income Dataset/',
			lang: '',
			adminEmailMd5: 'de8a7aa53d07e6b6bceb45c64027763d',
			tagMeta: ["管理员","小伙伴","访客",],
			master: ["de8a7aa53d07e6b6bceb45c64027763d",],
			friends: ["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc",],
			math: true,
			md: true,
			enableQQ: false,
			NoRecordIP: false,
			visitor: ,
			maxNest: 6,
			pageSize: 6,
			serverURLs: '',
			emoticonUrl: ["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest",],
		});
	}, window.MiniValine);
});
function getScript(url, callback, condition) {
	if (condition) {
	  callback();
	} else {
	  var script = document.createElement('script');
	  script.onload = script.onreadystatechange = function(_, isAbort) {
		if (isAbort || !script.readyState || /loaded|complete/.test(script.readyState)) {
		  script.onload = script.onreadystatechange = null;
		  script = undefined;
		  if (!isAbort && callback) setTimeout(callback, 0);
		}
	  };
	  script.src = url;
	  document.head.appendChild(script);
	}
}
function loadComments(element, callback) {
    if (!false || !element) {
      callback();
      return;
    }
    let intersectionObserver = new IntersectionObserver((entries, observer) => {
      let entry = entries[0];
      if (entry.isIntersecting) {
        callback();
        observer.disconnect();
      }
    });
    intersectionObserver.observe(element);
    return intersectionObserver;
}
</script>
    </div>
</body>
</html>
